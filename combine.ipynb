{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515f7f18",
   "metadata": {},
   "source": [
    "# Import packages, set matplotlib params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import gridspec\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['lines.markersize'] = 4.0\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e033dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 'Daily'\n",
    "frequency = 'Weekly'\n",
    "frequency = 'Monthly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fb43c",
   "metadata": {},
   "source": [
    "# Read `.xlsx` files into pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if frequency == 'Daily':\n",
    "    timecol = 'Trddt'\n",
    "    try:\n",
    "        df = pd.read_pickle(frequency + 'dataframeorigin.pkl')\n",
    "    except:\n",
    "        dfd0 = pd.read_excel('TRD_Dalyr.xlsx', header=0, usecols=[0, 1, 3], skiprows=[1, 2], parse_dates=[1])\n",
    "        dfd1 = pd.read_excel('TRD_Dalyr1.xlsx', header=0, usecols=[0, 1, 3], skiprows=[1, 2], parse_dates=[1])\n",
    "        dfd2 = pd.read_excel('TRD_Dalyr2.xlsx', header=0, usecols=[0, 1, 3], skiprows=[1, 2], parse_dates=[1])\n",
    "        dfd3 = pd.read_excel('TRD_Dalyr3.xlsx', header=0, usecols=[0, 1, 3], skiprows=[1, 2], parse_dates=[1])\n",
    "\n",
    "        df = pd.concat([dfd0, dfd1, dfd2, dfd3])\n",
    "elif frequency == 'Weekly':\n",
    "    timecol = 'Trdwnt'\n",
    "    try:\n",
    "        df = pd.read_pickle(frequency + 'dataframeorigin.pkl')\n",
    "    except:\n",
    "        dfw0 = pd.read_excel('TRD_Week.xlsx', header=0, usecols=[0, 1, 2], skiprows=[1, 2], parse_dates=[1])\n",
    "        dfw1 = pd.read_excel('TRD_Week1.xlsx', header=0, usecols=[0, 1, 2], skiprows=[1, 2], parse_dates=[1])\n",
    "        dfw2 = pd.read_excel('TRD_Week2.xlsx', header=0, usecols=[0, 1, 2], skiprows=[1, 2], parse_dates=[1])\n",
    "\n",
    "        df = pd.concat([dfw0, dfw1, dfw2])\n",
    "elif frequency == 'Monthly':\n",
    "    timecol = 'Trdmnt'\n",
    "    try:\n",
    "        df = pd.read_pickle(frequency + 'dataframeorigin.pkl')\n",
    "    except:\n",
    "        df = pd.read_excel('TRD_Mnth.xlsx', header=0, usecols=[0, 1, 2], skiprows=[1, 2], parse_dates=[1])\n",
    "\n",
    "df.to_pickle(frequency + 'dataframeorigin.pkl')\n",
    "qlist = np.arange(0, 1, 0.05)\n",
    "s = np.empty(len(qlist))\n",
    "for i in tqdm(range(len(qlist))):\n",
    "    nanaug = df.set_index([timecol, 'Stkcd']).unstack()\n",
    "    # nannumt = nanaug.T.isna().sum()\n",
    "    # nanaug = nanaug.T[nanaug.T.columns[nannumt < nannumt.quantile(qlist[i])]].T\n",
    "    nannums = nanaug.isna().sum()\n",
    "    s[i] = nanaug[nanaug.columns[nannums < nannums.quantile(qlist[i])]].dropna(axis='index', how='any').size\n",
    "q = qlist[s.argmax()]\n",
    "nanaug = df.set_index([timecol, 'Stkcd']).unstack()\n",
    "# nannumt = nanaug.T.isna().sum()\n",
    "# nanaug = nanaug.T[nanaug.T.columns[nannumt < nannumt.quantile(q)]].T\n",
    "nannums = nanaug.isna().sum()\n",
    "nanaug = nanaug[nanaug.columns[nannums < nannums.quantile(q)]].dropna(axis='index', how='any')\n",
    "stocks = nanaug.columns.droplevel().values\n",
    "df_valid = df[df['Stkcd'].isin(stocks)]\n",
    "df_valid.to_pickle(frequency + 'dataframevalid.pkl')\n",
    "df_valid.to_csv(frequency + 'dataframevalid.csv')\n",
    "df_cov = df_valid.set_index([timecol, 'Stkcd']).unstack().dropna(axis='index', how='any').cov()\n",
    "df_cov.to_pickle(frequency + 'dataframe.pkl')\n",
    "df_cov.to_csv(frequency + 'dataframe.csv')\n",
    "cov = df_cov.values \n",
    "assert ~np.any(np.isnan(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描述性统计\n",
    "stockcov = np.diagonal(cov)\n",
    "stockvar = pd.DataFrame(stockcov)\n",
    "stockvar.to_csv(frequency + 'StockVar.csv')\n",
    "stockvar.describe()\n",
    "\n",
    "# 绘制频率直方图\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, figsize=(9, 6))\n",
    "ax0.hist(stockcov, 100, density=True, histtype='bar', facecolor='blue', alpha=0.75)\n",
    "ax0.set_title(frequency + ' PDF')\n",
    "ax0.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax1.hist(stockcov, 20, density=True, histtype='bar', facecolor='yellowgreen', alpha=0.75, cumulative=True, rwidth=0.8)\n",
    "ax1.set_title(frequency + ' CDF')\n",
    "ax1.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "plt.show()\n",
    "fig.savefig(frequency + 'PDF.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95455852",
   "metadata": {},
   "source": [
    "# Calculate the risk expectation `V(n)` of n-combined stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N = len(cov) \n",
    "indices = np.arange(N) \n",
    "n = np.arange(1, min(201, cov.shape[0])) \n",
    "sampleN = 1000\n",
    "\n",
    "def averV(ni):\n",
    "    index = rng.choice(N, size=ni, replace=False) \n",
    "    return cov[index].T[index].sum() / ni / ni \n",
    "\n",
    "averVvec = np.vectorize(averV) \n",
    "\n",
    "aver = np.empty(len(n)) \n",
    "vmin = np.empty(len(n))\n",
    "vmax = np.empty(len(n))\n",
    "vstd = np.empty(len(n))\n",
    "vmed = np.empty(len(n))\n",
    "\n",
    "for i in tqdm(range(len(n))):\n",
    "    d = averVvec(np.full(sampleN, n[i]))\n",
    "    aver[i] = np.mean(d)\n",
    "    vmin[i] = np.min(d)\n",
    "    vmax[i] = np.max(d)\n",
    "    vstd[i] = np.std(d, ddof=-1)\n",
    "    vmed[i] = np.median(d)\n",
    "\n",
    "np.savetxt(frequency + 'numpydata.csv', np.vstack([n, aver, vstd, vmax, vmin]).T, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3867b41",
   "metadata": {},
   "source": [
    "# Draw the covariance matrix of first 10 stocks's risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52962e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "# fig.tight_layout()\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, left=0.15, right=0.95, top=0.9, bottom=0.15, wspace=0.4, hspace=0.5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "cp = ax.imshow(cov[:10, :10])\n",
    "fig.colorbar(cp, ax=ax)\n",
    "ax.set_xticks(np.arange(10))\n",
    "ax.set_xticklabels(np.arange(10).astype(str))\n",
    "ax.set_yticks(np.arange(10))\n",
    "ax.set_yticklabels(np.arange(10).astype(str))\n",
    "# fig.savefig('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224461d",
   "metadata": {},
   "source": [
    "# Draw the relation between risk expectation `V(n)` and `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4958be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "# fig.tight_layout()\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, left=0.15, right=0.95, top=0.9, bottom=0.15, wspace=0.4, hspace=0.5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "# ax = plt.subplot2grid((1,1),(0,0))\n",
    "ds = [averVvec(np.full(sampleN, 10)), averVvec(np.full(sampleN, 50)), averVvec(np.full(sampleN, 100))]\n",
    "for i, ni in enumerate([10, 50, 100]):\n",
    "    np.savetxt(frequency + str(ni) + '.csv', ds[i], delimiter=',')\n",
    "ax.boxplot(ds, positions=[10, 50, 100], sym='', patch_artist=True, widths=5)\n",
    "ax.plot(n, aver, color='b', label='E[Var(n)]')\n",
    "# ax.plot(n, vmed, color='y', label='Med[Var(n)]')\n",
    "ax.fill_between(n, aver - vstd, aver + vstd, color='b', alpha=0.3, label=r'$\\pm$Std[Var(n)]')\n",
    "ax.plot(n, vmax, color='g', label='Max[Var(n)]')\n",
    "ax.hlines(0.000144, 0, n.max(), label='CSI 300 Index')\n",
    "# ax.plot(n, vmin, color='y', label='Min[Var(n)]')\n",
    "ax.set_xlabel('n')\n",
    "ax.set_ylabel(frequency + ' Result')\n",
    "ax.grid()\n",
    "ax.yaxis.get_major_formatter().set_powerlimits((0, 1)) \n",
    "ax.legend()\n",
    "# ax.set_yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig(frequency + 'risk.png')\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a485707",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.trace(cov)\n",
    "covv = cov.sum() - var\n",
    "\n",
    "def V(n, a):\n",
    "    return (var / N - covv / N  / (N - 1)) / (n ** a) + covv / N  / (N - 1)\n",
    "\n",
    "# cost function\n",
    "least_squares = LeastSquares(n, aver, aver / np.sqrt(sampleN), V)\n",
    "\n",
    "# minimize the cost function and give the starting value of a\n",
    "m = Minuit(least_squares, a=1, name=('a'))\n",
    "m.limits['a'] = (0, 2)\n",
    "m.errordef = 1\n",
    "# finds minimum of least_squares function\n",
    "m.migrad()  # run optimiser\n",
    "# accurately computes uncertainties\n",
    "# m.hesse() \n",
    "m.minos()\n",
    "\n",
    "fit_info = []\n",
    "for p, v, e in zip(m.parameters, m.values, m.errors):\n",
    "    fit_info.append(f'{p} = ${v:.3f} \\\\pm {e:.3f}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18602ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "# fig.tight_layout()\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, left=0.15, right=0.95, top=0.9, bottom=0.15, wspace=0.4, hspace=0.5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.plot(n, aver, color='b', label='E[Var(n)]')\n",
    "# ax.fill_between(n, aver - vstd, aver + vstd, color='b', alpha=0.3, label=r'$\\pm$Std')\n",
    "# ax.plot(n, vmax, color='g', label='Max[Var(n)]')\n",
    "ax.plot(n, V(n, *m.values), color='r', label='fit E[Var(n)]')\n",
    "# ax.hlines(0.000144, 0, n.max(), label='CSI 300 Index')\n",
    "ax.set_xlabel('$n$')\n",
    "ax.set_ylabel('$V(n)=c_1 \\cdot n^{-a} + c_2$')\n",
    "ax.grid()\n",
    "ax.yaxis.get_major_formatter().set_powerlimits((0, 1))\n",
    "ax.legend(title='\\n'.join(fit_info))\n",
    "# ax.set_yscale('log')\n",
    "fig.savefig(frequency + 'fit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd188d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "# fig.tight_layout()\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, left=0.15, right=0.95, top=0.9, bottom=0.15, wspace=0.4, hspace=0.5)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "for timespan in ['Daily', 'Weekly', 'Monthly']:\n",
    "    aver = np.loadtxt(timespan + 'numpydata.csv', delimiter=',')[:, 1]\n",
    "    ax.plot(n[1:], np.diff(aver), label=timespan)\n",
    "ax.set_xlabel('n')\n",
    "ax.set_ylabel(\"V'(n)\")\n",
    "ax.grid()\n",
    "ax.yaxis.get_major_formatter().set_powerlimits((0, 1))\n",
    "ax.legend()\n",
    "# ax.set_yscale('log')\n",
    "fig.savefig('Comparation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
